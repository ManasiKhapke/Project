{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GT 740M (CNMeM is disabled)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import pylab\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pkl\n",
    "from lasagne import layers\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from theano.tensor.nnet import softmax\n",
    "from scipy.misc import imread, imresize\n",
    "from nolearn.lasagne import NeuralNet, BatchIterator\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "repo_location = '/workspace/project/project/'\n",
    "data_root = os.path.join(os.path.expanduser('~') + repo_location + 'datasets/')\n",
    "script_root = os.path.join(os.path.expanduser('~') + repo_location + 'scripts/')\n",
    "model_root = os.path.join(os.path.expanduser('~') + repo_location + 'models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions\n",
    "number = '0123456789'\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def classer(element):\n",
    "    if type(element) == unicode:\n",
    "        element = element.encode('ascii')\n",
    "    if (0 <= element < 10):\n",
    "        return (element)\n",
    "    elif (10 <= element < 36) :\n",
    "        return (alphabet[element - 10].upper())\n",
    "    elif (36 <= element < 62):\n",
    "        return (alphabet[element - 36])\n",
    "    elif element in alphabet or element in alphabet.upper() or element in number:\n",
    "        return element\n",
    "    else : \n",
    "        print 'do u recognize this? %r' % element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded chars74k\n",
      "Loaded icdar03\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# chars74k\n",
    "data1 = pd.read_csv(script_root + 'LISTFILE.txt', sep = ' ', header = None)\n",
    "print 'Loaded chars74k'\n",
    "\n",
    "# icdar03\n",
    "soup = bs(open(data_root + 'icdar03/train/char/char.xml').read(), 'lxml-xml')\n",
    "X = []\n",
    "y = []\n",
    "for image in soup('image'):\n",
    "    try:\n",
    "        img = imread(data_root + 'icdar03/train/char/' + image['file'])\n",
    "        X.append(img)\n",
    "        y.append(image['tag'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "data2 = pd.DataFrame({'image' : X, 'label' : y})\n",
    "# drop extra labels\n",
    "data2 = data2.loc[~data2['label'].isin([':', '-', '.', '\\'', '!', '(', '\"', ')', '&', '?', u'\\xa3', u'\\xc9', u'\\xd1', u'\\xe9'])]\n",
    "print 'Loaded icdar03'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chars74k reshaped and grayscaled\n",
      "icdar03 reshaped and grayscaled\n"
     ]
    }
   ],
   "source": [
    "# Reshape images to 32x32 and convert to grayscale\n",
    "# chars74k\n",
    "data1_x = np.zeros((data1[0].count(), 1, 32, 32))\n",
    "data1_y = map(classer, data1[1])\n",
    "\n",
    "for idx, path in enumerate(data1[0]):\n",
    "    img = imread(data_root + 'English/' + path)\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data1_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data1_x[idx, ...] = img\n",
    "        \n",
    "data1_x = data1_x.astype('float32')\n",
    "print 'chars74k reshaped and grayscaled'\n",
    "\n",
    "# icdar03\n",
    "data2_x = np.zeros((data2['image'].count(), 1, 32, 32))\n",
    "data2_y = map(classer, data2['label'].values)\n",
    "\n",
    "for idx, img in enumerate(data2['image']):\n",
    "    img = imresize(img, (32, 32))\n",
    "    if len(img.shape) == 3:\n",
    "        data2_x[idx, ...] = img.dot([0.299, 0.587, 0.144])\n",
    "    else:\n",
    "        data2_x[idx, ...] = img\n",
    "        \n",
    "data2_x = data2_x.astype('float32')\n",
    "print 'icdar03 reshaped and grayscaled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize by MuSigma\n",
    "data1_x /= data1_x.std(axis = None)\n",
    "data1_x -= data1_x.mean()\n",
    "\n",
    "data2_x /= data2_x.std(axis = None)\n",
    "data2_x -= data2_x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concat both datasets\n",
    "data_x = np.vstack((data1_x, data2_x))\n",
    "data_y = np.concatenate([data1_y, data2_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13818, 1, 32, 32) (13818,) <type 'numpy.ndarray'> <type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print data_x.shape, data_y.shape, type(data_x), type(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting nn \n",
    "net = NeuralNet(\n",
    "    layers = [\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),\n",
    "        ('conv3', layers.Conv2DLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "    ],\n",
    "\n",
    "    input_shape = (None, 1, 32, 32),\n",
    "    conv1_num_filters = 32, conv1_filter_size = (5, 5),\n",
    "    pool1_pool_size = (2, 2),\n",
    "    dropout1_p = 0.2,\n",
    "    conv2_num_filters = 64, conv2_filter_size = (5, 5),\n",
    "    pool2_pool_size = (2, 2),\n",
    "    dropout2_p = 0.2,\n",
    "    conv3_num_filters = 128, conv3_filter_size = (5, 5),\n",
    "    hidden4_num_units = 128,\n",
    "    output_num_units = 62, output_nonlinearity = softmax,\n",
    "\n",
    "    batch_iterator_train = BatchIterator(batch_size = 2500),\n",
    "    batch_iterator_test = BatchIterator(batch_size = 2500),\n",
    "\n",
    "    update_learning_rate = 0.01,\n",
    "    update_momentum = 0.9,\n",
    "\n",
    "    use_label_encoder = True,\n",
    "    regression = False,\n",
    "    max_epochs = 250,\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Neural Network with 281534 learnable parameters\n",
      "\n",
      "## Layer information\n",
      "\n",
      "  #  name      size\n",
      "---  --------  --------\n",
      "  0  input     1x32x32\n",
      "  1  conv1     32x28x28\n",
      "  2  pool1     32x14x14\n",
      "  3  dropout1  32x14x14\n",
      "  4  conv2     64x10x10\n",
      "  5  pool2     64x5x5\n",
      "  6  dropout2  64x5x5\n",
      "  7  conv3     128x1x1\n",
      "  8  hidden4   128\n",
      "  9  output    62\n",
      "\n",
      "  epoch    train loss    valid loss    train/val    valid acc  dur\n",
      "-------  ------------  ------------  -----------  -----------  ------\n",
      "      1       \u001b[36m4.14672\u001b[0m       \u001b[32m4.12919\u001b[0m      1.00424      0.01145  11.24s\n",
      "      2       \u001b[36m4.14237\u001b[0m       \u001b[32m4.12485\u001b[0m      1.00425      0.01684  11.02s\n",
      "      3       \u001b[36m4.13745\u001b[0m       \u001b[32m4.11984\u001b[0m      1.00427      0.02070  11.02s\n",
      "      4       \u001b[36m4.13313\u001b[0m       \u001b[32m4.11476\u001b[0m      1.00446      0.03168  11.00s\n",
      "      5       \u001b[36m4.12832\u001b[0m       \u001b[32m4.10984\u001b[0m      1.00450      0.04186  10.59s\n",
      "      6       \u001b[36m4.12364\u001b[0m       \u001b[32m4.10513\u001b[0m      1.00451      0.05051  11.16s\n",
      "      7       \u001b[36m4.11979\u001b[0m       \u001b[32m4.10049\u001b[0m      1.00471      0.06395  10.80s\n",
      "      8       \u001b[36m4.11649\u001b[0m       \u001b[32m4.09592\u001b[0m      1.00502      0.08012  10.80s\n",
      "      9       \u001b[36m4.11220\u001b[0m       \u001b[32m4.09121\u001b[0m      1.00513      0.09391  10.79s\n",
      "     10       \u001b[36m4.10884\u001b[0m       \u001b[32m4.08639\u001b[0m      1.00550      0.10283  11.14s\n",
      "     11       \u001b[36m4.10543\u001b[0m       \u001b[32m4.08141\u001b[0m      1.00589      0.11461  10.80s\n",
      "     12       \u001b[36m4.10061\u001b[0m       \u001b[32m4.07616\u001b[0m      1.00600      0.12579  11.40s\n",
      "     13       \u001b[36m4.09662\u001b[0m       \u001b[32m4.07068\u001b[0m      1.00637      0.13950  10.86s\n",
      "     14       \u001b[36m4.09298\u001b[0m       \u001b[32m4.06486\u001b[0m      1.00692      0.14915  10.57s\n",
      "     15       \u001b[36m4.08850\u001b[0m       \u001b[32m4.05864\u001b[0m      1.00736      0.15820  10.67s\n",
      "     16       \u001b[36m4.08434\u001b[0m       \u001b[32m4.05204\u001b[0m      1.00797      0.16499  10.56s\n",
      "     17       \u001b[36m4.07989\u001b[0m       \u001b[32m4.04498\u001b[0m      1.00863      0.16333  10.57s\n",
      "     18       \u001b[36m4.07472\u001b[0m       \u001b[32m4.03748\u001b[0m      1.00922      0.15761  10.57s\n",
      "     19       \u001b[36m4.06988\u001b[0m       \u001b[32m4.02943\u001b[0m      1.01004      0.14437  10.57s\n",
      "     20       \u001b[36m4.06459\u001b[0m       \u001b[32m4.02082\u001b[0m      1.01089      0.13712  10.57s\n",
      "     21       \u001b[36m4.05844\u001b[0m       \u001b[32m4.01166\u001b[0m      1.01166      0.13200  10.57s\n",
      "     22       \u001b[36m4.05304\u001b[0m       \u001b[32m4.00196\u001b[0m      1.01276      0.12029  10.57s\n",
      "     23       \u001b[36m4.04589\u001b[0m       \u001b[32m3.99153\u001b[0m      1.01362      0.11823  10.57s\n",
      "     24       \u001b[36m4.03873\u001b[0m       \u001b[32m3.98035\u001b[0m      1.01467      0.11198  10.57s\n",
      "     25       \u001b[36m4.03158\u001b[0m       \u001b[32m3.96837\u001b[0m      1.01593      0.10605  10.57s\n",
      "     26       \u001b[36m4.02417\u001b[0m       \u001b[32m3.95555\u001b[0m      1.01735      0.08955  10.57s\n",
      "     27       \u001b[36m4.01546\u001b[0m       \u001b[32m3.94185\u001b[0m      1.01867      0.08290  10.57s\n",
      "     28       \u001b[36m4.00585\u001b[0m       \u001b[32m3.92715\u001b[0m      1.02004      0.07066  10.57s\n",
      "     29       \u001b[36m3.99745\u001b[0m       \u001b[32m3.91167\u001b[0m      1.02193      0.05915  10.57s\n",
      "     30       \u001b[36m3.98891\u001b[0m       \u001b[32m3.89561\u001b[0m      1.02395      0.05263  10.91s\n",
      "     31       \u001b[36m3.97958\u001b[0m       \u001b[32m3.87902\u001b[0m      1.02592      0.04784  10.78s\n",
      "     32       \u001b[36m3.96826\u001b[0m       \u001b[32m3.86203\u001b[0m      1.02751      0.04578  11.32s\n",
      "     33       \u001b[36m3.95931\u001b[0m       \u001b[32m3.84506\u001b[0m      1.02971      0.04638  11.01s\n",
      "     34       \u001b[36m3.94883\u001b[0m       \u001b[32m3.82831\u001b[0m      1.03148      0.03966  10.79s\n",
      "     35       \u001b[36m3.93864\u001b[0m       \u001b[32m3.81201\u001b[0m      1.03322      0.03680  11.13s\n",
      "     36       \u001b[36m3.92745\u001b[0m       \u001b[32m3.79635\u001b[0m      1.03453      0.03740  10.82s\n",
      "     37       \u001b[36m3.91806\u001b[0m       \u001b[32m3.78144\u001b[0m      1.03613      0.03740  10.62s\n",
      "     38       \u001b[36m3.90872\u001b[0m       \u001b[32m3.76758\u001b[0m      1.03746      0.03720  11.01s\n",
      "     39       \u001b[36m3.90004\u001b[0m       \u001b[32m3.75496\u001b[0m      1.03864      0.03740  11.39s\n",
      "     40       \u001b[36m3.89231\u001b[0m       \u001b[32m3.74352\u001b[0m      1.03974      0.03840  11.76s\n",
      "     41       \u001b[36m3.88437\u001b[0m       \u001b[32m3.73327\u001b[0m      1.04047      0.03920  10.73s\n",
      "     42       \u001b[36m3.87778\u001b[0m       \u001b[32m3.72416\u001b[0m      1.04125      0.04000  10.83s\n",
      "     43       \u001b[36m3.86821\u001b[0m       \u001b[32m3.71568\u001b[0m      1.04105      0.03960  11.19s\n",
      "     44       \u001b[36m3.86312\u001b[0m       \u001b[32m3.70770\u001b[0m      1.04192      0.03980  10.89s\n",
      "     45       \u001b[36m3.85663\u001b[0m       \u001b[32m3.70063\u001b[0m      1.04216      0.03980  10.82s\n",
      "     46       \u001b[36m3.85029\u001b[0m       \u001b[32m3.69437\u001b[0m      1.04221      0.03940  10.61s\n",
      "     47       \u001b[36m3.84557\u001b[0m       \u001b[32m3.68882\u001b[0m      1.04249      0.03980  10.60s\n",
      "     48       \u001b[36m3.84040\u001b[0m       \u001b[32m3.68384\u001b[0m      1.04250      0.03960  10.77s\n",
      "     49       \u001b[36m3.83554\u001b[0m       \u001b[32m3.67957\u001b[0m      1.04239      0.04020  10.86s\n",
      "     50       \u001b[36m3.83263\u001b[0m       \u001b[32m3.67563\u001b[0m      1.04271      0.04060  11.12s\n",
      "     51       \u001b[36m3.82867\u001b[0m       \u001b[32m3.67224\u001b[0m      1.04260      0.04000  11.15s\n",
      "     52       \u001b[36m3.82550\u001b[0m       \u001b[32m3.66914\u001b[0m      1.04262      0.04020  10.78s\n",
      "     53       \u001b[36m3.82225\u001b[0m       \u001b[32m3.66635\u001b[0m      1.04252      0.04100  10.87s\n"
     ]
    }
   ],
   "source": [
    "# train nn\n",
    "net.fit(data_x, data_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
